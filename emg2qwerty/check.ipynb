{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce1a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from emg2qwerty import transforms, utils\n",
    "from hydra import initialize, compose\n",
    "from emg2qwerty.data import WindowedEMGDataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from emg2qwerty.transforms import Compose, ToTensor, LogSpectrogram, TemporalAlignmentJitter, IdentityTransform, RandomBandRotation, SlidingCovariance, SpecAugment, ZNormalizeTime\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import logging\n",
    "from emg2qwerty.lightning import WindowedEMGDataModule\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f4ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Train the emg2qwerty model. \n",
    "\n",
    "Code taken from: \n",
    "Sivakumar, Viswanath, et al. \n",
    "\"emg2qwerty: A large dataset with baselines for touch typing using surface electromyography.\" \n",
    "Advances in Neural Information Processing Systems 37 (2024): 91373-91389.\n",
    "\n",
    "https://github.com/facebookresearch/emg2qwerty\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d15ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "According to your setup, you need to change,\n",
    "\n",
    "dataset:\n",
    "  root: /mnt/dataDrive/qwertyData/data in base.yaml\n",
    "\n",
    "and \n",
    "lm_path: /mnt/dataDrive/emgFullCorpora/toUpload/emg2qwerty/models/wikitext-103-6gram-charlm.bin in ctc_beam.yaml\n",
    "\n",
    "in config files.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "All codes are same except that we use SlidingCovariance instead of log spectrogams.\n",
    "We also train for 250 epochs instead of 150 epochs since our model took longer to converge. \n",
    "\n",
    "The rest of the things are same as in https://github.com/facebookresearch/emg2qwerty.\n",
    "This is a controlled experiment to show that covariance features rae better than spectral features. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826698d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"deocder = ctc_beam or ctc_greedy\n",
    "approxDiag = (keep TRUE)\n",
    "\"\"\"\n",
    "\n",
    "user = \"user0\"\n",
    "decoder = \"ctc_greedy\" \n",
    "approxDiag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1c9e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path = \"config\", version_base = None):\n",
    "    config = compose(\n",
    "        config_name = \"base\",\n",
    "        overrides=[\n",
    "            f\"user={user}\",\n",
    "            f\"decoder={decoder}\"\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bc55f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/mnt/dataDrive/emgFullCorpora/toUpload/DATA/emg2qwerty/frechetMean/\" + user + \"Mean.pkl\", \"rb\") as f:\n",
    "    userMean = pickle.load(f)\n",
    "meanLeft = userMean[\"left\"]\n",
    "meanRight = userMean[\"right\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33070788",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvaluesL, eigenvectorsL = np.linalg.eig(meanLeft)\n",
    "\n",
    "eigenvaluesR, eigenvectorsR = np.linalg.eig(meanRight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df5b05f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvectorsLeft = torch.tensor(eigenvectorsL, dtype = torch.float32)\n",
    "eigenvectorsRight = torch.tensor(eigenvectorsR, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ddff167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullSessionPaths(dataset, root):\n",
    "    sessions = [s[\"session\"] for s in dataset]\n",
    "    return [Path(root) / f\"{session}.hdf5\" for session in sessions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85801c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': 'user0', 'dataset': {'train': [{'user': 43037958, 'session': '2020-12-17-1608244656-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-17-1608255062-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-17-1608257601-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-17-1608268481-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-18-1608304463-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-18-1608314177-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-18-1608311446-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-17-1608220409-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-17-1608223018-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-17-1608217769-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}], 'val': [{'user': 43037958, 'session': '2020-12-17-1608249257-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-18-1608306627-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}], 'test': [{'user': 43037958, 'session': '2020-12-17-1608247041-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-17-1608266139-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}], 'root': '/mnt/dataDrive/qwertyData/data'}, 'to_tensor': {'_target_': 'emg2qwerty.transforms.ToTensor', 'fields': ['emg_left', 'emg_right']}, 'band_rotation': {'_target_': 'emg2qwerty.transforms.ForEach', 'transform': {'_target_': 'emg2qwerty.transforms.RandomBandRotation', 'offsets': [-1, 0, 1]}}, 'temporal_jitter': {'_target_': 'emg2qwerty.transforms.TemporalAlignmentJitter', 'max_offset': 120}, 'logspec': {'_target_': 'emg2qwerty.transforms.LogSpectrogram', 'n_fft': 64, 'hop_length': 16}, 'specaug': {'_target_': 'emg2qwerty.transforms.SpecAugment', 'n_time_masks': 3, 'time_mask_param': 25, 'n_freq_masks': 2, 'freq_mask_param': 4}, 'bandwise_covariance': {'_target_': 'emg2qwerty.transforms.SlidingCovariance'}, 'flatten_spd': {'_target_': 'emg2qwerty.transforms.FlattenSPDSequence'}, 'transforms': {'train': ['${to_tensor}', '${band_rotation}', '${temporal_jitter}', '${bandwise_covariance}'], 'val': ['${to_tensor}', '${bandwise_covariance}'], 'test': '${transforms.val}'}, 'module': {'_target_': 'emg2qwerty.lightning.TDSConvCTCModule', 'in_features': 528, 'mlp_features': [384], 'block_channels': [24, 24, 24, 24], 'kernel_width': 32}, 'datamodule': {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}, 'optimizer': {'_target_': 'torch.optim.Adam', 'lr': 0.001, 'weight_decay': 0.001}, 'lr_scheduler': {'scheduler': {'_target_': 'pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR', 'warmup_epochs': 10, 'max_epochs': '${trainer.max_epochs}', 'warmup_start_lr': 1e-08, 'eta_min': 1e-06}, 'interval': 'epoch'}, 'decoder': {'_target_': 'emg2qwerty.decoder.CTCGreedyDecoder'}, 'seed': 0, 'batch_size': 32, 'num_workers': 4, 'train': True, 'checkpoint': None, 'monitor_metric': 'val/CER', 'monitor_mode': 'min', 'trainer': {'accelerator': 'gpu', 'devices': 1, 'num_nodes': 1, 'max_epochs': 250, 'default_root_dir': '${hydra:runtime.output_dir}', 'val_check_interval': 1.0}, 'callbacks': [{'_target_': 'pytorch_lightning.callbacks.LearningRateMonitor'}, {'_target_': 'pytorch_lightning.callbacks.ModelCheckpoint', 'dirpath': '${hydra:runtime.output_dir}/checkpoints', 'monitor': '${monitor_metric}', 'mode': '${monitor_mode}', 'save_last': True, 'verbose': True}]}\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d235c1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTransform = Compose([\n",
    "    ToTensor(fields=['emg_left', 'emg_right'], stack_dim = 1),\n",
    "    ZNormalizeTime(),\n",
    "    RandomBandRotation(),\n",
    "    TemporalAlignmentJitter(max_offset = 120, stack_dim = 1),\n",
    "    SlidingCovariance(eigenvectorsL = eigenvectorsLeft, eigenvectorsR = eigenvectorsRight, approxDiag = approxDiag)\n",
    "])\n",
    "\n",
    "valTransform = Compose([\n",
    "    ToTensor(fields=['emg_left', 'emg_right'], stack_dim = 1),\n",
    "    ZNormalizeTime(),\n",
    "    SlidingCovariance(eigenvectorsL = eigenvectorsLeft, eigenvectorsR = eigenvectorsRight, approxDiag = approxDiag)\n",
    "])\n",
    "\n",
    "testTransform = Compose([\n",
    "    ToTensor(fields=['emg_left', 'emg_right'], stack_dim = 1),\n",
    "    ZNormalizeTime(),\n",
    "    SlidingCovariance(eigenvectorsL = eigenvectorsLeft, eigenvectorsR = eigenvectorsRight, approxDiag = approxDiag)\n",
    "])\n",
    "\n",
    "trainSessions = fullSessionPaths(config.dataset.train, config.dataset.root)\n",
    "valSessions = fullSessionPaths(config.dataset.val, config.dataset.root)\n",
    "testSessions = fullSessionPaths(config.dataset.test, config.dataset.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5017281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = instantiate(\n",
    "    config.datamodule,\n",
    "    batch_size = config.batch_size,\n",
    "    num_workers = config.num_workers,\n",
    "    train_sessions = trainSessions,\n",
    "    val_sessions = valSessions,\n",
    "    test_sessions = testSessions,\n",
    "    train_transform = trainTransform,\n",
    "    val_transform = valTransform,\n",
    "    test_transform = testTransform,\n",
    "    _convert_ = \"object\"\n",
    ")\n",
    "\n",
    "\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7acc045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emg2qwerty.lightning import TDSConvCTCModule\n",
    "from emg2qwerty.charset import charset\n",
    "import torch.optim as optim\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2002a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TDSConvCTCModule(\n",
    "    in_features = 16 * 16,\n",
    "    mlp_features = config.module.mlp_features,\n",
    "    block_channels = config.module.block_channels,\n",
    "    kernel_width = config.module.kernel_width,\n",
    "    optimizer = config.optimizer,\n",
    "    lr_scheduler = config.lr_scheduler,\n",
    "    decoder = config.decoder,\n",
    "    share_hand_weights = False\n",
    ")\n",
    "\n",
    "checkpointCB = ModelCheckpoint(\n",
    "    monitor = 'val/loss',\n",
    "    save_top_k = 1,\n",
    "    mode = 'min',\n",
    "    filename = 'best-model',\n",
    "    save_last = True,\n",
    "    dirpath = './checkpoints'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67a4d81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "lrMonitor = LearningRateMonitor(logging_interval = 'epoch')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator = 'gpu',\n",
    "    devices = 1,\n",
    "    max_epochs = config.trainer.max_epochs,\n",
    "    callbacks = [checkpointCB, lrMonitor],\n",
    "    default_root_dir = './outputs',\n",
    "    log_every_n_steps = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c1fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Train the model. Skip this cell if you simpy want simply test with the given checkpoints. \"\"\"\n",
    "\n",
    "trainer.fit(model, datamodule = datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1739bbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if approxDiag:\n",
    "    where = \"withApproxDiag\"\n",
    "else: \n",
    "    where = \"withoutApproxDiag\"\n",
    "\n",
    "checkpoint = torch.load(\"/mnt/dataDrive/emgFullCorpora/toUpload/DATA/emg2qwerty/\" + where + \"/\" + user + \".ckpt\")\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3ecd4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:   5%|▌         | 1/20 [00:00<00:07,  2.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k2/miniconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608935911/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 20/20 [00:01<00:00, 13.44it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         val/CER            18.492643356323242\n",
      "         val/DER            2.8898062705993652\n",
      "         val/IER             4.837514400482178\n",
      "         val/SER             10.7653226852417\n",
      "        val/loss            0.9733709096908569\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val/loss': 0.9733709096908569,\n",
       "  'val/CER': 18.492643356323242,\n",
       "  'val/IER': 4.837514400482178,\n",
       "  'val/DER': 2.8898062705993652,\n",
       "  'val/SER': 10.7653226852417}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(model, datamodule = datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ad34e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:02<00:00,  1.04s/it]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test/CER            22.591007232666016\n",
      "        test/DER             2.002141237258911\n",
      "        test/IER             6.723768711090088\n",
      "        test/SER            13.865096092224121\n",
      "        test/loss           1.1161961555480957\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test/loss': 1.1161961555480957,\n",
       "  'test/CER': 22.591007232666016,\n",
       "  'test/IER': 6.723768711090088,\n",
       "  'test/DER': 2.002141237258911,\n",
       "  'test/SER': 13.865096092224121}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule = datamodule)         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emg2qwerty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
